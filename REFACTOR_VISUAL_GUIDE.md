# Moola Architecture Refactor - Visual Guide

## ğŸ¯ Before & After Comparison

### BEFORE: Current Structure (Cluttered)
```
moola/
â”œâ”€â”€ ğŸ“„ .mcp.json                       âŒ Empty, duplicates global
â”œâ”€â”€ ğŸ“„ .env                            âŒ Unused GLM_API_KEY
â”œâ”€â”€ ğŸ“„ claude_code_zai_env.sh          âŒ Duplicate of ~/dotfiles
â”œâ”€â”€ ğŸ“„ *_agent.md (4 files)            âŒ OpenCode agents (global)
â”œâ”€â”€ ğŸ“„ *_command.md (4 files)          âŒ OpenCode commands (global)
â”œâ”€â”€ ğŸ“„ model_174_baseline.pkl          âŒ Scattered artifact
â”œâ”€â”€ ğŸ“„ model_174_pretrained.pkl        âŒ Scattered artifact
â”œâ”€â”€ ğŸ“„ feature_metadata_174.json       âŒ Scattered metadata
â”œâ”€â”€ ğŸ“„ test_oof.npy                    âŒ Scattered OOF
â”œâ”€â”€ ğŸ“ test_splits/                    âŒ Duplicate of data/splits/
â”œâ”€â”€ ğŸ“ runpod_bundle_*/                âŒ Build artifacts at root
â”œâ”€â”€ ğŸ“ runpod_results/                 âŒ Duplicate of artifacts/
â”œâ”€â”€ ğŸ“„ CLEANUP_SUMMARY_*.md            âŒ Temporary docs
â”œâ”€â”€ ğŸ“„ WELCOME_BACK.md                 âŒ Temporary docs
â”œâ”€â”€ ğŸ“ data/
â”‚   â”œâ”€â”€ processed/
â”‚   â”‚   â”œâ”€â”€ train_latest.parquet       âš ï¸  Unclear: 4D or 11D?
â”‚   â”‚   â”œâ”€â”€ train_clean.parquet        âš ï¸  Unclear: 98 or 174 samples?
â”‚   â”‚   â”œâ”€â”€ train_combined_174.parquet âš ï¸  Unclear: Why 3 versions?
â”‚   â”‚   â”œâ”€â”€ train_combined_175.parquet âš ï¸  Unclear: Why 3 versions?
â”‚   â”‚   â”œâ”€â”€ train_combined_178.parquet âš ï¸  Unclear: Why 3 versions?
â”‚   â”‚   â””â”€â”€ train_smote_300.parquet    âš ï¸  Unclear: Synthetic?
â”‚   â”œâ”€â”€ pretraining/
â”‚   â”‚   â”œâ”€â”€ unlabeled_features.npy     âš ï¸  Unclear: 4D or 11D?
â”‚   â”‚   â””â”€â”€ unlabeled_ohlc.npy         âš ï¸  Unclear: Same as features?
â”‚   â””â”€â”€ oof/
â”‚       â”œâ”€â”€ simple_lstm_clean.npy      âš ï¸  Unclear: Supervised or pretrained?
â”‚       â””â”€â”€ simple_lstm_augmented.npy  âš ï¸  Unclear: What augmentation?
â””â”€â”€ ğŸ“ models/
    â””â”€â”€ pretrained/
        â””â”€â”€ bilstm_encoder.pt          âš ï¸  Unclear: Encoder or model?
```

### AFTER: Proposed Structure (Clean)
```
moola/
â”œâ”€â”€ ğŸ“„ .env.example                    âœ… Example only (no secrets)
â”œâ”€â”€ ğŸ“„ .gitignore                      âœ… Essential
â”œâ”€â”€ ğŸ“„ pyproject.toml                  âœ… Essential
â”œâ”€â”€ ğŸ“„ Makefile                        âœ… Essential
â”œâ”€â”€ ğŸ“„ README.md                       âœ… Essential
â”œâ”€â”€ ğŸ“„ CLAUDE.md                       âœ… Essential (Claude Code context)
â”œâ”€â”€ ğŸ“„ RUNPOD_QUICK_START.md           âœ… Essential (workflow guide)
â”‚
â”œâ”€â”€ ğŸ“ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”œâ”€â”€ unlabeled/
â”‚   â”‚   â”‚   â””â”€â”€ unlabeled_windows.parquet  # 2.2M samples, 4D OHLC
â”‚   â”‚   â””â”€â”€ labeled/
â”‚   â”‚       â””â”€â”€ (future: raw labeled data)
â”‚   â”‚
â”‚   â”œâ”€â”€ processed/
â”‚   â”‚   â”œâ”€â”€ unlabeled/
â”‚   â”‚   â”‚   â”œâ”€â”€ unlabeled_4d_ohlc.npy      # 2.2M Ã— (105, 4)
â”‚   â”‚   â”‚   â””â”€â”€ unlabeled_11d_relative.npy # 2.2M Ã— (105, 11)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ labeled/
â”‚   â”‚   â”‚   â”œâ”€â”€ train_latest.parquet       # 174 samples (current)
â”‚   â”‚   â”‚   â”œâ”€â”€ train_latest_4d.npy        # 174 Ã— (105, 4)
â”‚   â”‚   â”‚   â”œâ”€â”€ train_latest_11d.npy       # 174 Ã— (105, 11)
â”‚   â”‚   â”‚   â””â”€â”€ metadata/
â”‚   â”‚   â”‚       â”œâ”€â”€ feature_metadata_174.json
â”‚   â”‚   â”‚       â””â”€â”€ dataset_manifest.json
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ archived/
â”‚   â”‚       â”œâ”€â”€ train_clean.parquet        # 98 samples (before batch 200)
â”‚   â”‚       â”œâ”€â”€ train_combined_174.parquet # Historical
â”‚   â”‚       â”œâ”€â”€ train_smote_300.parquet    # Synthetic augmentation
â”‚   â”‚       â””â”€â”€ README.md                  # Explains each dataset
â”‚   â”‚
â”‚   â”œâ”€â”€ splits/                            # Train/val/test splits
â”‚   â”œâ”€â”€ batches/                           # Annotation batches
â”‚   â””â”€â”€ corrections/                       # Human annotations
â”‚
â””â”€â”€ ğŸ“ artifacts/
    â”œâ”€â”€ encoders/
    â”‚   â”œâ”€â”€ pretrained/
    â”‚   â”‚   â”œâ”€â”€ bilstm_mae_4d_v1.pt        # BiLSTM MAE (4D OHLC)
    â”‚   â”‚   â”œâ”€â”€ bilstm_mae_11d_v1.pt       # BiLSTM MAE (11D Relative)
    â”‚   â”‚   â”œâ”€â”€ ts2vec_encoder_v1.pt       # TS2Vec contrastive
    â”‚   â”‚   â””â”€â”€ tstcc_encoder_v1.pt        # TSTCC contrastive
    â”‚   â””â”€â”€ supervised/
    â”‚       â””â”€â”€ (future: encoder blocks from supervised training)
    â”‚
    â”œâ”€â”€ models/
    â”‚   â”œâ”€â”€ supervised/                    # No pretraining
    â”‚   â”‚   â”œâ”€â”€ simple_lstm_baseline_174.pkl
    â”‚   â”‚   â”œâ”€â”€ enhanced_simple_lstm_174.pkl
    â”‚   â”‚   â”œâ”€â”€ cnn_transformer_174.pkl
    â”‚   â”‚   â”œâ”€â”€ rwkv_ts_174.pkl
    â”‚   â”‚   â”œâ”€â”€ logreg_174.pkl
    â”‚   â”‚   â”œâ”€â”€ rf_174.pkl
    â”‚   â”‚   â””â”€â”€ xgb_174.pkl
    â”‚   â”‚
    â”‚   â”œâ”€â”€ pretrained/                    # Fine-tuned from pretrained encoders
    â”‚   â”‚   â”œâ”€â”€ simple_lstm_bilstm_mae_4d_174.pkl
    â”‚   â”‚   â”œâ”€â”€ simple_lstm_bilstm_mae_11d_174.pkl
    â”‚   â”‚   â””â”€â”€ enhanced_simple_lstm_ts2vec_174.pkl
    â”‚   â”‚
    â”‚   â””â”€â”€ ensemble/                      # Stacking ensemble
    â”‚       â”œâ”€â”€ stack_rf_meta_174.pkl
    â”‚       â””â”€â”€ stack_logreg_meta_174.pkl
    â”‚
    â”œâ”€â”€ oof/                               # Out-of-fold predictions
    â”‚   â”œâ”€â”€ supervised/
    â”‚   â”‚   â”œâ”€â”€ simple_lstm_174.npy
    â”‚   â”‚   â”œâ”€â”€ enhanced_simple_lstm_174.npy
    â”‚   â”‚   â”œâ”€â”€ cnn_transformer_174.npy
    â”‚   â”‚   â”œâ”€â”€ logreg_174.npy
    â”‚   â”‚   â”œâ”€â”€ rf_174.npy
    â”‚   â”‚   â””â”€â”€ xgb_174.npy
    â”‚   â””â”€â”€ pretrained/
    â”‚       â”œâ”€â”€ simple_lstm_bilstm_mae_4d_174.npy
    â”‚       â””â”€â”€ simple_lstm_bilstm_mae_11d_174.npy
    â”‚
    â”œâ”€â”€ metadata/
    â”‚   â”œâ”€â”€ feature_metadata_174.json
    â”‚   â”œâ”€â”€ dataset_manifest.json
    â”‚   â””â”€â”€ experiment_registry.json
    â”‚
    â”œâ”€â”€ runpod_bundles/
    â”‚   â”œâ”€â”€ runpod_bundle_20251020_013740.tar.gz
    â”‚   â””â”€â”€ runpod_bundle_build/
    â”‚
    â””â”€â”€ runpod_results/
        â”œâ”€â”€ phase2_results.csv
        â””â”€â”€ oof/
```

---

## ğŸ”„ Data Flow: Unlabeled â†’ Labeled â†’ Models

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RAW DATA (Never Modified)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data/raw/unlabeled/unlabeled_windows.parquet                    â”‚
â”‚   â€¢ 2.2M samples                                                â”‚
â”‚   â€¢ 105 bars Ã— 4 channels (OHLC)                                â”‚
â”‚   â€¢ Source: NQ futures 1-min data                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PROCESSED UNLABELED (For Pretraining)              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data/processed/unlabeled/                                       â”‚
â”‚   â”œâ”€â”€ unlabeled_4d_ohlc.npy       # (2.2M, 105, 4)             â”‚
â”‚   â””â”€â”€ unlabeled_11d_relative.npy  # (2.2M, 105, 11)            â”‚
â”‚                                                                 â”‚
â”‚ Feature Transform:                                              â”‚
â”‚   4D OHLC â†’ 11D RelativeTransform                               â”‚
â”‚   [O, H, L, C] â†’ [O_rel, H_rel, L_rel, C_rel, range, body,     â”‚
â”‚                   upper_wick, lower_wick, HL_mid, OC_mid, vol] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  PRETRAINED ENCODERS                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ artifacts/encoders/pretrained/                                  â”‚
â”‚   â”œâ”€â”€ bilstm_mae_4d_v1.pt         # Masked Autoencoder (4D)    â”‚
â”‚   â”œâ”€â”€ bilstm_mae_11d_v1.pt        # Masked Autoencoder (11D)   â”‚
â”‚   â”œâ”€â”€ ts2vec_encoder_v1.pt        # TS2Vec contrastive         â”‚
â”‚   â””â”€â”€ tstcc_encoder_v1.pt         # TSTCC contrastive          â”‚
â”‚                                                                 â”‚
â”‚ Self-Supervised Learning:                                       â”‚
â”‚   â€¢ Masked Autoencoder: Mask 15% of timesteps, reconstruct     â”‚
â”‚   â€¢ TS2Vec: Hierarchical contrastive learning                  â”‚
â”‚   â€¢ TSTCC: Temporal contrastive coding                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PROCESSED LABELED (For Supervised Training)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data/processed/labeled/                                         â”‚
â”‚   â”œâ”€â”€ train_latest.parquet        # 174 samples (current)      â”‚
â”‚   â”œâ”€â”€ train_latest_4d.npy         # (174, 105, 4)              â”‚
â”‚   â”œâ”€â”€ train_latest_11d.npy        # (174, 105, 11)             â”‚
â”‚   â””â”€â”€ metadata/                                                 â”‚
â”‚       â”œâ”€â”€ feature_metadata_174.json                             â”‚
â”‚       â””â”€â”€ dataset_manifest.json                                 â”‚
â”‚                                                                 â”‚
â”‚ Source: Human annotations via Candlesticks project              â”‚
â”‚   â€¢ Batch 200: 33 keepers (16.6% keeper rate)                  â”‚
â”‚   â€¢ Previous batches: 141 samples                               â”‚
â”‚   â€¢ Total: 174 labeled samples                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SUPERVISED MODELS                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ artifacts/models/supervised/  (No pretraining)                  â”‚
â”‚   â”œâ”€â”€ simple_lstm_baseline_174.pkl                              â”‚
â”‚   â”œâ”€â”€ enhanced_simple_lstm_174.pkl                              â”‚
â”‚   â”œâ”€â”€ cnn_transformer_174.pkl                                   â”‚
â”‚   â”œâ”€â”€ rwkv_ts_174.pkl                                           â”‚
â”‚   â”œâ”€â”€ logreg_174.pkl                                            â”‚
â”‚   â”œâ”€â”€ rf_174.pkl                                                â”‚
â”‚   â””â”€â”€ xgb_174.pkl                                               â”‚
â”‚                                                                 â”‚
â”‚ artifacts/models/pretrained/  (Fine-tuned from pretrained)      â”‚
â”‚   â”œâ”€â”€ simple_lstm_bilstm_mae_4d_174.pkl                         â”‚
â”‚   â”œâ”€â”€ simple_lstm_bilstm_mae_11d_174.pkl                        â”‚
â”‚   â””â”€â”€ enhanced_simple_lstm_ts2vec_174.pkl                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                OUT-OF-FOLD PREDICTIONS                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ artifacts/oof/supervised/                                       â”‚
â”‚   â”œâ”€â”€ simple_lstm_174.npy         # (174, 2) probabilities     â”‚
â”‚   â”œâ”€â”€ enhanced_simple_lstm_174.npy                              â”‚
â”‚   â”œâ”€â”€ cnn_transformer_174.npy                                   â”‚
â”‚   â”œâ”€â”€ logreg_174.npy                                            â”‚
â”‚   â”œâ”€â”€ rf_174.npy                                                â”‚
â”‚   â””â”€â”€ xgb_174.npy                                               â”‚
â”‚                                                                 â”‚
â”‚ artifacts/oof/pretrained/                                       â”‚
â”‚   â”œâ”€â”€ simple_lstm_bilstm_mae_4d_174.npy                         â”‚
â”‚   â””â”€â”€ simple_lstm_bilstm_mae_11d_174.npy                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ENSEMBLE MODELS                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ artifacts/models/ensemble/                                      â”‚
â”‚   â”œâ”€â”€ stack_rf_meta_174.pkl       # Random Forest meta-learner â”‚
â”‚   â””â”€â”€ stack_logreg_meta_174.pkl   # Logistic Regression meta   â”‚
â”‚                                                                 â”‚
â”‚ Stacking Strategy:                                              â”‚
â”‚   â€¢ Input: OOF predictions from all base models                 â”‚
â”‚   â€¢ Meta-learner: Random Forest or Logistic Regression          â”‚
â”‚   â€¢ Output: Final ensemble prediction                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ—ï¸ Encoder vs Model vs Weights Taxonomy

### Terminology Clarification

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         ENCODER                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Definition: Reusable feature extraction block                    â”‚
â”‚                                                                  â”‚
â”‚ Examples:                                                        â”‚
â”‚   â€¢ BiLSTM encoder (128 hidden units)                            â”‚
â”‚   â€¢ RWKV-TS time-mixing block                                    â”‚
â”‚   â€¢ CNN-Transformer local convolution block                      â”‚
â”‚                                                                  â”‚
â”‚ Characteristics:                                                 â”‚
â”‚   â€¢ Input: (batch, seq_len, features)                            â”‚
â”‚   â€¢ Output: (batch, seq_len, hidden_dim) or (batch, hidden_dim) â”‚
â”‚   â€¢ No classification head                                       â”‚
â”‚   â€¢ Can be pretrained or trained from scratch                    â”‚
â”‚   â€¢ Can be frozen or fine-tuned                                  â”‚
â”‚                                                                  â”‚
â”‚ Storage:                                                         â”‚
â”‚   artifacts/encoders/pretrained/bilstm_mae_4d_v1.pt              â”‚
â”‚   artifacts/encoders/supervised/rwkv_ts_encoder_174.pt           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          MODEL                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Definition: Complete architecture for training/inference         â”‚
â”‚                                                                  â”‚
â”‚ Examples:                                                        â”‚
â”‚   â€¢ EnhancedSimpleLSTM = BiLSTM encoder + attention + classifier â”‚
â”‚   â€¢ CNN-Transformer = CNN encoder + Transformer + classifier     â”‚
â”‚   â€¢ RWKV-TS = RWKV encoder + classifier                          â”‚
â”‚                                                                  â”‚
â”‚ Characteristics:                                                 â”‚
â”‚   â€¢ Input: (batch, seq_len, features)                            â”‚
â”‚   â€¢ Output: (batch, num_classes) logits or probabilities         â”‚
â”‚   â€¢ Includes classification head                                 â”‚
â”‚   â€¢ Can load pretrained encoder weights                          â”‚
â”‚   â€¢ Trained end-to-end on labeled data                           â”‚
â”‚                                                                  â”‚
â”‚ Storage:                                                         â”‚
â”‚   artifacts/models/supervised/enhanced_simple_lstm_174.pkl       â”‚
â”‚   artifacts/models/pretrained/simple_lstm_bilstm_mae_4d_174.pkl  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         WEIGHTS                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Definition: Saved checkpoint (encoder or model)                  â”‚
â”‚                                                                  â”‚
â”‚ Types:                                                           â”‚
â”‚   1. Pretrained encoder weights (.pt)                            â”‚
â”‚      â€¢ From self-supervised learning                             â”‚
â”‚      â€¢ Can be loaded into multiple models                        â”‚
â”‚      â€¢ Example: bilstm_mae_4d_v1.pt                              â”‚
â”‚                                                                  â”‚
â”‚   2. Fine-tuned model weights (.pkl)                             â”‚
â”‚      â€¢ From supervised training                                  â”‚
â”‚      â€¢ Includes encoder + classifier                             â”‚
â”‚      â€¢ Example: simple_lstm_bilstm_mae_4d_174.pkl                â”‚
â”‚                                                                  â”‚
â”‚   3. Ensemble meta-learner weights (.pkl)                        â”‚
â”‚      â€¢ From stacking ensemble training                           â”‚
â”‚      â€¢ Example: stack_rf_meta_174.pkl                            â”‚
â”‚                                                                  â”‚
â”‚ File Extensions:                                                 â”‚
â”‚   â€¢ .pt  = PyTorch state_dict (encoder only)                     â”‚
â”‚   â€¢ .pkl = Pickled model (encoder + classifier)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Example: SimpleLSTM with Pretrained BiLSTM Encoder

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PRETRAINING PHASE                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Input: 2.2M unlabeled windows (4D OHLC)                         â”‚
â”‚   â†“                                                             â”‚
â”‚ BiLSTM Masked Autoencoder                                       â”‚
â”‚   â€¢ Encoder: BiLSTM (128 hidden)                                â”‚
â”‚   â€¢ Decoder: MLP (reconstruct masked values)                    â”‚
â”‚   â€¢ Loss: MSE on masked timesteps                               â”‚
â”‚   â†“                                                             â”‚
â”‚ Save encoder weights only:                                      â”‚
â”‚   artifacts/encoders/pretrained/bilstm_mae_4d_v1.pt             â”‚
â”‚   â€¢ Contains: BiLSTM state_dict                                 â”‚
â”‚   â€¢ Size: ~500KB                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   FINE-TUNING PHASE                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Input: 174 labeled windows (4D OHLC)                            â”‚
â”‚   â†“                                                             â”‚
â”‚ SimpleLSTM Model                                                â”‚
â”‚   â€¢ Load pretrained encoder:                                    â”‚
â”‚     bilstm_mae_4d_v1.pt â†’ BiLSTM (128 hidden)                   â”‚
â”‚   â€¢ Freeze encoder (first 10 epochs)                            â”‚
â”‚   â€¢ Add classifier: Linear(128 â†’ 2)                             â”‚
â”‚   â€¢ Train on labeled data                                       â”‚
â”‚   â€¢ Unfreeze encoder (last 10 epochs)                           â”‚
â”‚   â†“                                                             â”‚
â”‚ Save complete model:                                            â”‚
â”‚   artifacts/models/pretrained/simple_lstm_bilstm_mae_4d_174.pkl â”‚
â”‚   â€¢ Contains: BiLSTM + classifier state_dict                    â”‚
â”‚   â€¢ Size: ~600KB                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Naming Convention Examples

### Encoders
```
Format: {architecture}_{pretraining_method}_{features}_v{version}.pt

bilstm_mae_4d_v1.pt              # BiLSTM, Masked Autoencoder, 4D OHLC, v1
bilstm_mae_11d_v1.pt             # BiLSTM, Masked Autoencoder, 11D Relative, v1
ts2vec_encoder_v1.pt             # TS2Vec, contrastive, v1
tstcc_encoder_v1.pt              # TSTCC, contrastive, v1
rwkv_ts_encoder_v1.pt            # RWKV-TS, state-space, v1
```

### Models (Supervised)
```
Format: {architecture}_{dataset_size}.pkl

simple_lstm_baseline_174.pkl     # SimpleLSTM, no pretraining, 174 samples
enhanced_simple_lstm_174.pkl     # EnhancedSimpleLSTM, no pretraining, 174 samples
cnn_transformer_174.pkl          # CNN-Transformer, no pretraining, 174 samples
rwkv_ts_174.pkl                  # RWKV-TS, no pretraining, 174 samples
logreg_174.pkl                   # Logistic Regression, 174 samples
rf_174.pkl                       # Random Forest, 174 samples
xgb_174.pkl                      # XGBoost, 174 samples
```

### Models (Pretrained)
```
Format: {architecture}_{encoder}_{features}_{dataset_size}.pkl

simple_lstm_bilstm_mae_4d_174.pkl       # SimpleLSTM + BiLSTM MAE (4D), 174 samples
simple_lstm_bilstm_mae_11d_174.pkl      # SimpleLSTM + BiLSTM MAE (11D), 174 samples
enhanced_simple_lstm_ts2vec_174.pkl     # EnhancedSimpleLSTM + TS2Vec, 174 samples
cnn_transformer_tstcc_174.pkl           # CNN-Transformer + TSTCC, 174 samples
```

### OOF Predictions
```
Format: {architecture}_{encoder}_{features}_{dataset_size}.npy

# Supervised (no pretraining)
simple_lstm_174.npy              # SimpleLSTM, 174 samples
enhanced_simple_lstm_174.npy     # EnhancedSimpleLSTM, 174 samples

# Pretrained
simple_lstm_bilstm_mae_4d_174.npy       # SimpleLSTM + BiLSTM MAE (4D), 174 samples
simple_lstm_bilstm_mae_11d_174.npy      # SimpleLSTM + BiLSTM MAE (11D), 174 samples
```

---

## ğŸ” Quick Reference: Where to Find Things

### "Where is the current training dataset?"
```
data/processed/labeled/train_latest.parquet  # 174 samples (current)
```

### "Where are the pretrained encoder weights?"
```
artifacts/encoders/pretrained/bilstm_mae_4d_v1.pt  # BiLSTM MAE (4D OHLC)
artifacts/encoders/pretrained/bilstm_mae_11d_v1.pt # BiLSTM MAE (11D Relative)
```

### "Where are the trained models?"
```
artifacts/models/supervised/enhanced_simple_lstm_174.pkl  # No pretraining
artifacts/models/pretrained/simple_lstm_bilstm_mae_4d_174.pkl  # With pretraining
```

### "Where are the OOF predictions for stacking?"
```
artifacts/oof/supervised/simple_lstm_174.npy
artifacts/oof/supervised/enhanced_simple_lstm_174.npy
artifacts/oof/supervised/cnn_transformer_174.npy
artifacts/oof/supervised/logreg_174.npy
artifacts/oof/supervised/rf_174.npy
artifacts/oof/supervised/xgb_174.npy
```

### "Where is the unlabeled data for pretraining?"
```
data/raw/unlabeled/unlabeled_windows.parquet  # 2.2M samples (raw)
data/processed/unlabeled/unlabeled_4d_ohlc.npy  # 2.2M samples (processed, 4D)
data/processed/unlabeled/unlabeled_11d_relative.npy  # 2.2M samples (processed, 11D)
```

### "Where are the annotation batches?"
```
data/batches/batch_200.parquet  # Latest batch
data/batches/batch_200_clean_keepers.parquet  # 33 keepers
```

### "Where are the historical datasets?"
```
data/processed/archived/train_clean.parquet  # 98 samples (before batch 200)
data/processed/archived/train_combined_174.parquet  # Historical
data/processed/archived/train_smote_300.parquet  # Synthetic augmentation
```

---

## âœ… Checklist: Post-Refactor Verification

### Root Directory
- [ ] Only essential files at root (â‰¤15 files)
- [ ] No AI agent configs (.mcp.json, .env, *_agent.md, *_command.md)
- [ ] No scattered artifacts (model_*.pkl, feature_*.json, test_*.npy)
- [ ] No duplicate directories (test_splits/, runpod_results/)
- [ ] .env.example exists (no secrets)

### Data Directory
- [ ] Clear separation: raw/ vs processed/
- [ ] Clear separation: unlabeled/ vs labeled/
- [ ] Clear naming: 4D vs 11D features
- [ ] Historical datasets archived with README
- [ ] OOF predictions organized by source (supervised/pretrained)

### Artifacts Directory
- [ ] Encoders separated from models
- [ ] Pretrained encoders clearly named
- [ ] Models organized by training type (supervised/pretrained/ensemble)
- [ ] Consistent naming convention
- [ ] Metadata directory exists

### Code
- [ ] All path references updated
- [ ] Tests pass
- [ ] CLI commands work
- [ ] RunPod bundle creation works

### Documentation
- [ ] CLAUDE.md updated
- [ ] README.md updated
- [ ] docs/ARCHITECTURE.md updated
- [ ] Migration guide created

