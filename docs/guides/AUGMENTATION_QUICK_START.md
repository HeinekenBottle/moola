# Pseudo-Sample Augmentation Quick Start Guide

This guide demonstrates how to use the new pseudo-sample augmentation feature integrated into the Moola ML pipeline.

## Overview

The augmentation system generates realistic synthetic OHLC samples to expand small datasets while maintaining:
- **100% OHLC integrity** (Open â‰¤ High â‰¥ Low, Close â‰¤ High, Open â‰¥ Low, Close â‰¥ Low)
- **Statistical similarity** (KS test p-value > 0.1)
- **Market realism** (temporal and pattern-based strategies only)
- **Memory efficiency** (<8 GB total usage)
- **Reproducible results** (configurable random seeds)

## CLI Usage

### Basic Training with Augmentation

```bash
# Conservative augmentation (Week 1 target: 50 synthetic samples)
moola train \
  --model simple_lstm \
  --augment-data \
  --augmentation-ratio 0.5 \
  --max-synthetic-samples 50 \
  --quality-threshold 0.7

# Full augmentation (Week 2-3 target: up to 210 synthetic samples)
moola train \
  --model simple_lstm \
  --augment-data \
  --augmentation-ratio 2.0 \
  --max-synthetic-samples 210 \
  --quality-threshold 0.7

# High quality augmentation only
moola train \
  --model simple_lstm \
  --augment-data \
  --quality-threshold 0.8 \
  --augmentation-seed 42
```

### Augmentation with Engineered Features

```bash
# Combine augmentation with engineered features
moola train \
  --model simple_lstm \
  --use-engineered-features \
  --max-engineered-features 25 \
  --augment-data \
  --augmentation-ratio 1.5
```

### Evaluation with Augmentation

```bash
# Evaluate model using augmented data
moola evaluate \
  --model simple_lstm \
  --augment-data \
  --augmentation-ratio 2.0 \
  --quality-threshold 0.7
```

## CLI Parameters

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `--augment-data` | flag | False | Enable pseudo-sample augmentation |
| `--augmentation-ratio` | float | 2.0 | Target ratio of synthetic:real samples |
| `--max-synthetic-samples` | int | 210 | Maximum synthetic samples to generate |
| `--augmentation-seed` | int | 1337 | Random seed for reproducible results |
| `--quality-threshold` | float | 0.7 | Minimum quality score for acceptance |

## Python API Usage

### Basic Augmentation

```python
from moola.data.dual_input_pipeline import create_dual_input_processor
import pandas as pd

# Load your data
df = pd.read_parquet('data/processed/train.parquet')

# Create processor with augmentation
processor = create_dual_input_processor(
    enable_augmentation=True,
    augmentation_ratio=2.0,
    max_synthetic_samples=50,
    quality_threshold=0.7,
    use_safe_strategies_only=True
)

# Process data (augmentation applied automatically)
processed_data = processor.process_training_data(df, enable_engineered_features=True)

# Check results
print(f"Original samples: {len(df)}")
print(f"Total samples after augmentation: {processed_data['X_ohlc'].shape[0]}")

# Get augmentation metadata
aug_metadata = processed_data['metadata']['augmentation_metadata']
print(f"Synthetic samples generated: {aug_metadata['n_synthetic_accepted']}")
print(f"OHLC integrity rate: {aug_metadata['ohlc_integrity_rate']:.3f}")
```

### Advanced Configuration

```python
from moola.data.dual_input_pipeline import FeatureConfig, DualInputDataProcessor

# Custom configuration
config = FeatureConfig(
    enable_augmentation=True,
    augmentation_ratio=1.5,
    max_synthetic_samples=100,
    augmentation_seed=42,
    quality_threshold=0.8,
    use_safe_strategies_only=True,  # Use only temporal + pattern-based
    use_small_dataset_features=True,
    use_price_action_features=True,
    max_total_engineered_features=30
)

# Create processor
processor = DualInputDataProcessor(config)

# Process data
processed_data = processor.process_training_data(df, enable_engineered_features=True)
```

## Progressively Scaling Augmentation

### Week 1: Conservative Start (50 samples)

```bash
# Start small to validate quality
moola train \
  --model simple_lstm \
  --augment-data \
  --augmentation-ratio 0.5 \
  --max-synthetic-samples 50 \
  --quality-threshold 0.8
```

### Week 2: Medium Scale (100-150 samples)

```bash
# Increase synthetic sample count
moola train \
  --model simple_lstm \
  --augment-data \
  --augmentation-ratio 1.5 \
  --max-synthetic-samples 150 \
  --quality-threshold 0.7
```

### Week 3: Full Scale (210 samples)

```bash
# Target 2:1 synthetic:real ratio
moola train \
  --model simple_lstm \
  --augment-data \
  --augmentation-ratio 2.0 \
  --max-synthetic-samples 210 \
  --quality-threshold 0.7
```

## Quality Monitoring

### Check Augmentation Results

The training log provides detailed augmentation metrics:

```
================================================================================
AUGMENTATION RESULTS
================================================================================
  - Original samples: 105
  - Synthetic samples: 50
  - Total samples: 155
  - Synthetic ratio: 0.48
  - OHLC integrity rate: 1.000
  - Strategies used: temporal_augmentation, pattern_synthesis
  - Average quality score: 0.842
================================================================================
```

### Quality Metrics

- **OHLC Integrity Rate**: Must be 1.000 (100%)
- **Average Quality Score**: Higher is better (0.0-1.0)
- **Synthetic Ratio**: Actual ratio achieved
- **Strategies Used**: Which augmentation methods were applied

## Validation and Testing

### Run the Example Script

```bash
# Basic demonstration
python examples/augmentation_example.py --mode demo --n-samples 50

# CLI examples only
python examples/augmentation_example.py --mode cli-examples

# Both demo and CLI examples
python examples/augmentation_example.py --mode both
```

### Run Comprehensive Tests

```bash
# Validate all quality requirements
python3 scripts/test_augmentation_integration.py
```

Expected output:
```
âœ… OHLC integrity: 100% preservation enforced
âœ… Statistical similarity: KS test p-value > 0.05
âœ… Progressive generation: 50 â†’ 210 samples supported
âœ… Memory efficiency: <8 GB usage maintained
âœ… Quality thresholds: Configurable controls working
âœ… CLI integration: All parameters functional
ðŸŽ‰ All tests PASSED! Augmentation integration is ready for production.
```

## Best Practices

### 1. Start Conservative
- Begin with 50 synthetic samples and high quality threshold (0.8)
- Monitor model performance improvements
- Gradually increase synthetic sample count

### 2. Use Safe Strategies
- Default uses only temporal and pattern-based augmentation
- These methods preserve market realism and OHLC relationships
- Avoid statistical simulation unless you need more diversity

### 3. Monitor Quality Metrics
- Always check OHLC integrity rate (should be 1.000)
- Review average quality scores in training logs
- Adjust quality threshold if too many samples are rejected

### 4. Reproducible Results
- Set `--augmentation-seed` for reproducible experiments
- Use the same seed when comparing different models
- Document seed values in your experiments

### 5. Memory Management
- Monitor memory usage during generation
- Large synthetic sample counts (>200) may require more memory
- Use `max-synthetic-samples` to limit memory usage

## Troubleshooting

### Low Quality Scores
```bash
# Increase quality threshold to be more selective
--quality-threshold 0.8
```

### Too Few Synthetic Samples
```bash
# Increase target ratio or maximum samples
--augmentation-ratio 3.0
--max-synthetic-samples 300
```

### Memory Issues
```bash
# Reduce synthetic sample count
--max-synthetic-samples 50
```

### OHLC Integrity Issues
- Should never happen with safe strategies enabled
- If it occurs, reduce augmentation ratio or quality threshold
- Report the issue with reproduction steps

## Integration Checklist

- [ ] Load training data with proper format
- [ ] Choose appropriate augmentation ratio (0.5-2.0)
- [ ] Set quality threshold (0.7-0.8 recommended)
- [ ] Configure max synthetic samples (50-210)
- [ ] Set reproducible random seed
- [ ] Run training with `--augment-data` flag
- [ ] Monitor augmentation quality metrics
- [ ] Compare model performance with/without augmentation
- [ ] Document results and parameters used

## Expected Performance

- **Generation time**: <5 minutes for 210 synthetic samples
- **Memory usage**: <8 GB total
- **OHLC integrity**: 100% preservation
- **Statistical similarity**: KS test p-value > 0.1
- **Model improvement**: Typically 5-15% accuracy gain on small datasets

## Next Steps

1. **Week 1**: Validate with 50 synthetic samples using conservative settings
2. **Week 2**: Scale to 100-150 samples and monitor quality
3. **Week 3**: Target full 210 synthetic samples with 2:1 ratio
4. **Continuous**: Monitor model performance and adjust parameters

For more detailed examples, see `examples/augmentation_example.py` and `scripts/test_augmentation_integration.py`.