"""Out-of-fold (OOF) prediction generation for ensemble stacking.

OOF predictions are generated by K-fold cross-validation:
1. Split data into K folds using shared split manifests
2. For each fold, train model on K-1 folds
3. Predict probabilities on the held-out fold
4. Concatenate all fold predictions into [N, C] matrix

This ensures no data leakage when training the meta-learner.
"""

from pathlib import Path

import numpy as np
from loguru import logger

from ..models import get_model
from ..utils.splits import get_or_create_splits


def generate_oof(
    X: np.ndarray,
    y: np.ndarray,
    model_name: str,
    seed: int,
    k: int,
    splits_dir: Path,
    output_path: Path,
    **model_kwargs,
) -> np.ndarray:
    """Generate out-of-fold predictions for a given model.

    Args:
        X: Feature matrix of shape [N, D]
        y: Target labels of shape [N]
        model_name: Model name (logreg, rf, xgb)
        seed: Random seed for reproducibility
        k: Number of folds
        splits_dir: Directory containing split manifests
        output_path: Path to save OOF predictions (.npy file)
        **model_kwargs: Additional model hyperparameters

    Returns:
        OOF predictions of shape [N, C] where C is number of classes

    Side Effects:
        - Creates split manifests in splits_dir if they don't exist
        - Saves OOF predictions to output_path
        - Creates .build.lock during write operations
    """
    logger.info(f"Generating OOF predictions | model={model_name} seed={seed} k={k}")

    # Get or create shared splits
    splits = get_or_create_splits(X, y, seed=seed, k=k, splits_dir=splits_dir)

    # Get number of classes from unique labels
    n_samples = len(y)
    n_classes = len(np.unique(y))

    # Initialize OOF prediction matrix [N, C]
    oof_predictions = np.zeros((n_samples, n_classes), dtype=np.float64)

    logger.info(f"OOF matrix shape: {oof_predictions.shape}")

    # Generate OOF predictions for each fold
    for fold_idx, (train_idx, val_idx) in enumerate(splits):
        logger.info(
            f"Fold {fold_idx + 1}/{k} | train={len(train_idx)} val={len(val_idx)}"
        )

        X_train, X_val = X[train_idx], X[val_idx]
        y_train, y_val = y[train_idx], y[val_idx]

        # Train model on K-1 folds
        model = get_model(model_name, seed=seed, **model_kwargs)
        model.fit(X_train, y_train)

        # Predict probabilities on held-out fold
        val_proba = model.predict_proba(X_val)

        # Store predictions in OOF matrix
        oof_predictions[val_idx] = val_proba

        # Log fold metrics
        val_pred = model.predict(X_val)
        fold_acc = (val_pred == y_val).mean()
        logger.info(f"Fold {fold_idx + 1} accuracy: {fold_acc:.3f}")

    # Verify no zero rows (all samples should have predictions)
    zero_rows = np.where(np.all(oof_predictions == 0, axis=1))[0]
    if len(zero_rows) > 0:
        logger.warning(f"Found {len(zero_rows)} rows with all-zero predictions")
    else:
        logger.info("All samples have non-zero OOF predictions")

    # Create .build.lock during write
    output_path.parent.mkdir(parents=True, exist_ok=True)
    lock_file = output_path.parent / ".build.lock"

    try:
        lock_file.touch()
        logger.info(f"Created .build.lock at {lock_file}")

        # Save OOF predictions
        np.save(output_path, oof_predictions)
        logger.info(f"Saved OOF predictions to {output_path} | shape={oof_predictions.shape}")
    finally:
        # Remove lock file after write completes
        if lock_file.exists():
            lock_file.unlink()
            logger.info(f"Removed .build.lock")

    return oof_predictions
