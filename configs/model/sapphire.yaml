# Sapphire Model Configuration
# moola-preenc-fr-s-v1.0 // codename: Sapphire
# Pre-trained encoder with frozen weights

model:
  name: sapphire
  base: jade  # Inherits from Jade
  
  # Transfer learning
  pretrained_encoder_path: artifacts/encoders/pretrained/bilstm_mae_11d_v1.pt
  freeze_encoder: true
  
  # Lightweight head (encoder frozen)
  architecture:
    hidden_size: 128
    num_layers: 2
    input_dropout: 0.25  # Stones: 0.2-0.3
    recurrent_dropout: 0.65  # Stones: 0.6-0.7 (inter-layer)
    dense_dropout: 0.5  # Stones: 0.4-0.5

# Inherits augmentation, uncertainty, gates from Jade

