{
  "phase": 4,
  "description": "Bootstrap confidence intervals for robust performance estimation on small datasets",
  "purpose": "Quantify uncertainty in model performance metrics when validation set is small (34 samples)",
  "bootstrap": {
    "enabled": true,
    "n_resamples": 1000,
    "confidence_level": 0.95,
    "random_seed": 42,
    "rationale": "1000 resamples provides stable CI estimates while keeping computation tractable"
  },
  "metrics": {
    "accuracy": {
      "enabled": true,
      "description": "Classification accuracy with 95% confidence interval"
    },
    "pointer_regression": {
      "enabled": true,
      "description": "Start/end MAE, hit rates with uncertainty quantification",
      "tolerance": 3,
      "key_metrics": ["start_mae", "end_mae", "hit_at_pm3", "center_mae"]
    },
    "calibration": {
      "enabled": true,
      "description": "ECE, MCE, Brier score with bootstrap CIs",
      "key_metrics": ["ece", "brier"]
    }
  },
  "expected_benefits": {
    "robust_estimation": "Account for uncertainty in small validation sets (34 samples)",
    "confidence_intervals": "95% CI provides range of plausible performance values",
    "model_selection": "Compare models with uncertainty quantification (non-overlapping CIs = significant difference)",
    "reporting": "Honest uncertainty estimates for stakeholders",
    "example": "Accuracy: 0.8529 [95% CI: 0.7647 - 0.9118] vs point estimate 0.8529"
  },
  "small_sample_considerations": {
    "validation_size": 34,
    "typical_ci_width": "~15-20 percentage points for accuracy",
    "interpretation": "Wide CIs reflect true uncertainty with small validation sets",
    "avoid": "Do not over-interpret small differences in point estimates without checking CI overlap"
  },
  "cli_usage": {
    "default": {
      "command": "python3 -m moola.cli train --model enhanced_simple_lstm --bootstrap-ci --device cuda",
      "description": "Enable bootstrap CI with default settings (1000 resamples, 95% confidence)"
    },
    "custom_resamples": {
      "command": "python3 -m moola.cli train --model enhanced_simple_lstm --bootstrap-ci --bootstrap-resamples 2000 --device cuda",
      "description": "Use 2000 resamples for more stable CI estimates (slower)"
    },
    "99_percent_ci": {
      "command": "python3 -m moola.cli train --model enhanced_simple_lstm --bootstrap-ci --bootstrap-confidence 0.99 --device cuda",
      "description": "Compute 99% confidence intervals (wider CIs)"
    },
    "minimal_resamples": {
      "command": "python3 -m moola.cli train --model enhanced_simple_lstm --bootstrap-ci --bootstrap-resamples 500 --device cuda",
      "description": "Fast bootstrap for debugging (500 resamples, less stable)"
    }
  },
  "example_output": {
    "classification": "Accuracy: 0.8529 [95% CI: 0.7647 - 0.9118]",
    "pointer_regression": "Start MAE: 2.34 [95% CI: 1.82 - 2.91], Hit@Â±3: 0.7353 [95% CI: 0.6176 - 0.8382]",
    "calibration": "ECE: 0.0234 [95% CI: 0.0156 - 0.0318], Brier: 0.1245 [95% CI: 0.0987 - 0.1521]"
  },
  "interpretation_guide": {
    "overlapping_cis": "Cannot confidently say Model A is better than Model B",
    "non_overlapping_cis": "Strong evidence Model A outperforms Model B",
    "wide_cis": "High uncertainty due to small validation set - need more data or more resamples",
    "narrow_cis": "Low uncertainty - consistent performance across resamples"
  },
  "computational_cost": {
    "baseline_evaluation": "~5 seconds (CPU)",
    "bootstrap_1000_resamples": "~8 seconds additional (CPU)",
    "bootstrap_2000_resamples": "~15 seconds additional (CPU)",
    "note": "Bootstrap is CPU-only, runs after GPU training completes"
  },
  "recommended_workflow": {
    "step1": "Train model with bootstrap CI enabled",
    "step2": "Check if CIs are wide (>15% for accuracy) - indicates high uncertainty",
    "step3": "Compare multiple models - only trust differences with non-overlapping CIs",
    "step4": "Report both point estimate and CI in experiment logs",
    "step5": "If CIs too wide, consider: (a) more validation data, (b) cross-validation, (c) MC Dropout"
  }
}
